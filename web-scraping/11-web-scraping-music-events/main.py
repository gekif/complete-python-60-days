from config import URL
import requests
import selectorlib

def scrape(url):
    """Scrape the page source from the URL"""
    response = requests.get(url)
    source = response.text
    return source

def extract(source):
    extractor = selectorlib.Extractor.from_yaml_file("extract.yaml")
    value = extractor.extract(source)["tours"]
    return value

def send_email():
    print("Email was sent")

def store(extracted):
    with open("data.txt", "a") as file:
        file.write(extracted + "\n")

def read():
    try:
        with open("data.txt", "r") as file:
            return file.read()
    except FileNotFoundError:
        return ""


if __name__ == "__main__":
    scraped = scrape(URL)
    extracted = extract(scraped)
    print(extracted)
    content = read()

    if extracted != "No upcoming tours":
        if extracted not in content:
            store(extracted)
            send_email()

